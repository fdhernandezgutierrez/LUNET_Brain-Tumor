{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdhernandezgutierrez/LUNET_Brain-Tumor/blob/main/nnUNet_test_on_BRaTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "188KYUdpn8y0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install triton\n",
        "!git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "!pip install -e ./nnUNet\n",
        "!pip install --upgrade git+https://github.com/nanohanno/hiddenlayer.git@bugfix/get_trace_graph#egg=hiddenlayer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "from batchgenerators.utilities.file_and_folder_operations import *\n",
        "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json"
      ],
      "metadata": {
        "id": "zIJH2kqmoCSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!mkdir -p /content/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/Dataset101_BraTS2021\n",
        "!mkdir -p /content/brats2021/training\n",
        "%cd /content/brats2021/training\n",
        "!tar xvf /content/drive/MyDrive/Colab\\ Notebooks/datafolder/BRATS2021/BraTS2021_Training_Data.tar\n",
        "os.environ['nnUNet_raw'] = \"/content/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/\"\n",
        "os.environ['nnUNet_results'] = '/content/RESULTS_FOLDER'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'"
      ],
      "metadata": {
        "id": "5xRUqOl_oFMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nnunetv2.paths import nnUNet_raw"
      ],
      "metadata": {
        "id": "4b0MXu-LoJoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_BraTS_segmentation_and_convert_labels_to_nnUNet(in_file: str, out_file: str) -> None:\n",
        "    # use this for segmentation only!!!\n",
        "    # nnUNet wants the labels to be continuous. BraTS is 0, 1, 2, 4 -> we make that into 0, 1, 2, 3\n",
        "    img = sitk.ReadImage(in_file)\n",
        "    img_npy = sitk.GetArrayFromImage(img)\n",
        "\n",
        "    uniques = np.unique(img_npy)\n",
        "    for u in uniques:\n",
        "        if u not in [0, 1, 2, 4]:\n",
        "            raise RuntimeError('unexpected label')\n",
        "\n",
        "    seg_new = np.zeros_like(img_npy)\n",
        "    seg_new[img_npy == 4] = 3\n",
        "    seg_new[img_npy == 2] = 1\n",
        "    seg_new[img_npy == 1] = 2\n",
        "    img_corr = sitk.GetImageFromArray(seg_new)\n",
        "    img_corr.CopyInformation(img)\n",
        "    sitk.WriteImage(img_corr, out_file)\n",
        "\n",
        "\n",
        "def convert_labels_back_to_BraTS(seg: np.ndarray):\n",
        "    new_seg = np.zeros_like(seg)\n",
        "    new_seg[seg == 1] = 2\n",
        "    new_seg[seg == 3] = 4\n",
        "    new_seg[seg == 2] = 1\n",
        "    return new_seg\n",
        "\n",
        "\n",
        "def load_convert_labels_back_to_BraTS(filename, input_folder, output_folder):\n",
        "    a = sitk.ReadImage(join(input_folder, filename))\n",
        "    b = sitk.GetArrayFromImage(a)\n",
        "    c = convert_labels_back_to_BraTS(b)\n",
        "    d = sitk.GetImageFromArray(c)\n",
        "    d.CopyInformation(a)\n",
        "    sitk.WriteImage(d, join(output_folder, filename))\n",
        "\n",
        "\n",
        "def convert_folder_with_preds_back_to_BraTS_labeling_convention(input_folder: str, output_folder: str, num_processes: int = 12):\n",
        "    \"\"\"\n",
        "    reads all prediction files (nifti) in the input folder, converts the labels back to BraTS convention and saves the\n",
        "    \"\"\"\n",
        "    maybe_mkdir_p(output_folder)\n",
        "    nii = subfiles(input_folder, suffix='.nii.gz', join=False)\n",
        "    with multiprocessing.get_context(\"spawn\").Pool(num_processes) as p:\n",
        "        p.starmap(load_convert_labels_back_to_BraTS, zip(nii, [input_folder] * len(nii), [output_folder] * len(nii)))"
      ],
      "metadata": {
        "id": "hLvcop8FoPmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brats_data_dir = '/content/brats2021/training'\n",
        "\n",
        "task_id = 101\n",
        "task_name = \"BraTS2021\"\n",
        "\n",
        "foldername = \"Dataset%03.0d_%s\" % (task_id, task_name)\n",
        "\n",
        "# setting up nnU-Net folders\n",
        "out_base = join(nnUNet_raw, foldername)\n",
        "imagestr = join(out_base, \"imagesTr\")\n",
        "labelstr = join(out_base, \"labelsTr\")\n",
        "imagests = join(out_base, \"imagesTs\")\n",
        "labelsts = join(out_base, \"labelsTs\")\n",
        "maybe_mkdir_p(imagestr)\n",
        "maybe_mkdir_p(labelstr)\n",
        "maybe_mkdir_p(imagests)\n",
        "maybe_mkdir_p(labelsts)\n",
        "\n",
        "case_ids = subdirs(brats_data_dir, prefix='BraTS', join=False)\n",
        "\n",
        "random.shuffle(case_ids)\n",
        "\n",
        "train_percentage = 0.8\n",
        "train_size = int(len(case_ids) * train_percentage)\n",
        "\n",
        "for i, c in enumerate(case_ids):\n",
        "    if i < train_size:\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t1.nii.gz\"), join(imagestr, c + '_0000.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t1ce.nii.gz\"), join(imagestr, c + '_0001.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t2.nii.gz\"), join(imagestr, c + '_0002.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_flair.nii.gz\"), join(imagestr, c + '_0003.nii.gz'))\n",
        "\n",
        "      copy_BraTS_segmentation_and_convert_labels_to_nnUNet(join(brats_data_dir, c, c + \"_seg.nii.gz\"),\n",
        "                                                          join(labelstr, c + '.nii.gz'))\n",
        "    else:\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t1.nii.gz\"), join(imagests, c + '_0000.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t1ce.nii.gz\"), join(imagests, c + '_0001.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_t2.nii.gz\"), join(imagests, c + '_0002.nii.gz'))\n",
        "      shutil.copy(join(brats_data_dir, c, c + \"_flair.nii.gz\"), join(imagests, c + '_0003.nii.gz'))\n",
        "\n",
        "      copy_BraTS_segmentation_and_convert_labels_to_nnUNet(join(brats_data_dir, c, c + \"_seg.nii.gz\"),\n",
        "                                                          join(labelsts, c + '.nii.gz'))\n",
        "generate_dataset_json(out_base,\n",
        "                      channel_names={0: 'T1', 1: 'T1ce', 2: 'T2', 3: 'Flair'},\n",
        "                      labels={\n",
        "                          'background': 0,\n",
        "                          'whole tumor': (1, 2, 3),\n",
        "                          'tumor core': (2, 3),\n",
        "                          'enhancing tumor': (3, )\n",
        "                      },\n",
        "                      num_training_cases = train_size,\n",
        "                      file_ending='.nii.gz',\n",
        "                      regions_class_order=(1, 2, 3),\n",
        "                      license='see https://www.synapse.org/#!Synapse:syn25829067/wiki/610863',\n",
        "                      reference='see https://www.synapse.org/#!Synapse:syn25829067/wiki/610863',\n",
        "                      dataset_release='1.0')"
      ],
      "metadata": {
        "id": "B8o8HuhEoVCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/brats2021dataset /content/drive/MyDrive/Colab\\ Notebooks/datafolder"
      ],
      "metadata": {
        "id": "YcxBHUjKwgqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['nnUNet_raw'] = \"/content/drive/MyDrive/Colab Notebooks/datafolder/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/\"\n",
        "os.environ['nnUNet_results'] = '/content/RESULTS_FOLDER'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "!mkdir -p /content/RESULTS_FOLDER\n",
        "!mkdir -p /content/nnUNet_preprocessed"
      ],
      "metadata": {
        "id": "-4yVXBstSlOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_plan_and_preprocess -d 101 --verify_dataset_integrity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLId-hzTTii_",
        "outputId": "85807cf9-9987-4dce-8874-e3d500a52640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fingerprint extraction...\n",
            "Dataset101_BraTS2021\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "\n",
            "####################\n",
            "verify_dataset_integrity Done. \n",
            "If you didn't see any error messages then your dataset is most likely OK!\n",
            "####################\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "100% 1000/1000 [19:02<00:00,  1.14s/it]\n",
            "Experiment planning...\n",
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [140. 171. 137.], 3d_lowres: [140, 171, 137]\n",
            "2D U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': (192, 160), 'median_image_size_in_voxels': array([171., 137.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
            "\n",
            "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
            "3D fullres U-Net configuration:\n",
            "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (128, 128, 128), 'median_image_size_in_voxels': array([140., 171., 137.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
            "\n",
            "Plans were saved to /content/nnUNet_preprocessed/Dataset101_BraTS2021/nnUNetPlans.json\n",
            "Preprocessing...\n",
            "Preprocessing dataset Dataset101_BraTS2021\n",
            "Configuration: 2d...\n",
            "100% 1000/1000 [42:37<00:00,  2.56s/it]\n",
            "Configuration: 3d_fullres...\n",
            "100% 1000/1000 [39:59<00:00,  2.40s/it]\n",
            "Configuration: 3d_lowres...\n",
            "INFO: Configuration 3d_lowres not found in plans file nnUNetPlans.json of dataset Dataset101_BraTS2021. Skipping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/nnUNet_preprocessed /content/drive/MyDrive/Colab\\ Notebooks/datafolder"
      ],
      "metadata": {
        "id": "_r6yKODBHani"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['nnUNet_raw'] = \"/content/drive/MyDrive/Colab Notebooks/datafolder/brats2021dataset/nnUNet_raw_data_base/nnUNet_raw_data/\"\n",
        "os.environ['nnUNet_results'] = '/content/RESULTS_FOLDER'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/drive/MyDrive/Colab Notebooks/datafolder/nnUNet_preprocessed'\n",
        "!mkdir -p /content/RESULTS_FOLDER\n",
        "!mkdir -p /content/nnUNet_preprocessed"
      ],
      "metadata": {
        "id": "JIrDPeszqHEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNetv2_train 101 2d 0 --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH6ptlqPcryj",
        "outputId": "88c5cc77-ce67-4c90-ef2d-ed24e730df2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############################\n",
            "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
            "############################\n",
            "\n",
            "Using device: cuda:0\n",
            "/content/nnUNet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
            "\n",
            "#######################################################################\n",
            "Please cite the following paper when using nnU-Net:\n",
            "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
            "#######################################################################\n",
            "\n",
            "2024-09-22 07:40:11.641665: do_dummy_2d_data_aug: False\n",
            "2024-09-22 07:40:19.288845: Creating new 5-fold cross-validation split...\n",
            "2024-09-22 07:40:19.306578: Desired fold for training: 0\n",
            "2024-09-22 07:40:19.306711: This split has 800 training and 200 validation cases.\n",
            "using pin_memory on device 0\n",
            "using pin_memory on device 0\n",
            "2024-09-22 07:48:20.586704: Using torch.compile...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "\n",
            "This is the configuration used by this training:\n",
            "Configuration name: 2d\n",
            " {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [171.0, 137.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
            "\n",
            "These are the global plan.json settings:\n",
            " {'dataset_name': 'Dataset101_BraTS2021', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 171, 137], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 100487.5078125, 'mean': 886.6679077148438, 'median': 402.0, 'min': 0.10992202162742615, 'percentile_00_5': 52.55787925720213, 'percentile_99_5': 7137.0, 'std': 2226.63232421875}, '1': {'max': 1905559.25, 'mean': 1805.9501953125, 'median': 544.0, 'min': 0.0, 'percentile_00_5': 45.0, 'percentile_99_5': 8668.0, 'std': 20990.86328125}, '2': {'max': 4438107.0, 'mean': 2476.2294921875, 'median': 745.0, 'min': 0.0, 'percentile_00_5': 111.0, 'percentile_99_5': 12326.0, 'std': 50532.6015625}, '3': {'max': 580014.3125, 'mean': 1044.1220703125, 'median': 510.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 14297.0, 'std': 5172.76123046875}}} \n",
            "\n",
            "2024-09-22 07:48:23.624143: unpacking dataset...\n",
            "2024-09-22 07:54:11.542012: unpacking done...\n",
            "2024-09-22 07:54:12.116036: Unable to plot network architecture: nnUNet_compile is enabled!\n",
            "2024-09-22 07:54:12.183258: \n",
            "2024-09-22 07:54:12.183434: Epoch 0\n",
            "2024-09-22 07:54:12.183661: Current learning rate: 0.01\n",
            "W0922 07:54:30.790000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:30.890000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:30.993000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:31.096000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:31.197000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:48.052000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:50.916000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:52.233000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:52.285000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:52.749000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:52.808000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:53.365000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:53.419000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:53.790000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:53.846000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:55.133000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:55.235000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:56.209000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:56.541000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:56.870000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:57.150000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 07:54:58.191000 140135089800768 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n",
            "W0922 08:08:42.246000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 08:08:42.372000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 08:08:42.518000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 08:08:42.704000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n",
            "W0922 08:08:42.874000 140139634659968 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n",
            "2024-09-22 08:12:09.678258: train_loss -0.3978\n",
            "2024-09-22 08:12:09.680546: val_loss -0.7633\n",
            "2024-09-22 08:12:09.680934: Pseudo dice [0.8729, 0.7943, 0.8109]\n",
            "2024-09-22 08:12:09.681205: Epoch time: 1077.5 s\n",
            "2024-09-22 08:12:09.681323: Yayy! New best EMA pseudo Dice: 0.826\n",
            "2024-09-22 08:12:11.479705: \n",
            "2024-09-22 08:12:11.480103: Epoch 1\n",
            "2024-09-22 08:12:11.480279: Current learning rate: 0.00999\n",
            "2024-09-22 08:27:29.336835: train_loss -0.8225\n",
            "2024-09-22 08:27:29.338026: val_loss -0.8369\n",
            "2024-09-22 08:27:29.338175: Pseudo dice [0.9045, 0.8629, 0.8708]\n",
            "2024-09-22 08:27:29.338318: Epoch time: 917.86 s\n",
            "2024-09-22 08:27:29.338404: Yayy! New best EMA pseudo Dice: 0.8314\n",
            "2024-09-22 08:27:31.439536: \n",
            "2024-09-22 08:27:31.439939: Epoch 2\n",
            "2024-09-22 08:27:31.440054: Current learning rate: 0.00998\n"
          ]
        }
      ]
    }
  ]
}